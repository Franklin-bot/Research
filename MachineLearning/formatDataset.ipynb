{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use venv ~opensim/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random index for IMU sensor\n",
    "def sampleSensor(sensorName):\n",
    "    index = random.randint(0, 49)\n",
    "    return sensorName if index == 0 else sensorName + str(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleDataInstance(data):\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = data[:, i] / max(abs(data[:, i]))\n",
    "    return data\n",
    "\n",
    "\n",
    "# take max abs value of each channel\n",
    "# divide all values by max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeZeros(data):\n",
    "    return np.delete(data, [0, 16], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIMUDataInstance(quaternion_data, velocity_data, acceleration_data, orientation_only = False):\n",
    "    # Get indices for sensors to use in this data instance\n",
    "    humerus_l_imu_tag = \"humerus_l_imu\"\n",
    "    humerus_r_imu_tag = \"humerus_r_imu\"\n",
    "    ulna_l_imu_tag = \"ulna_l_imu\"\n",
    "    ulna_r_imu_tag = \"ulna_r_imu\"\n",
    "    tags = [humerus_l_imu_tag, humerus_r_imu_tag, ulna_l_imu_tag, ulna_r_imu_tag]\n",
    "\n",
    "    concatenated = []\n",
    "    for tag in tags:\n",
    "        raw_q = quaternion_data[tag].values\n",
    "        raw_v = velocity_data[tag].values\n",
    "        raw_a = acceleration_data[tag].values\n",
    "\n",
    "        if not orientation_only:\n",
    "            total = np.zeros([raw_q.shape[0], 10])\n",
    "            for i in range(raw_q.shape[0]):\n",
    "                total[i, :4] = np.array(raw_q[i].split(',')).astype(float)\n",
    "                total[i, 4:7] = np.array(raw_v[i].split(',')).astype(float)\n",
    "                total[i, 7:] = np.array(raw_a[i].split(',')).astype(float)\n",
    "        else:\n",
    "            total = np.zeros([raw_q.shape[0], 4])\n",
    "            for i in range(raw_q.shape[0]):\n",
    "                total[i, :4] = np.array(raw_q[i].split(',')).astype(float)\n",
    "        \n",
    "        concatenated.append(total)\n",
    "\n",
    "    concatenated_data = np.concatenate(concatenated, axis=1)\n",
    "    return concatenated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDataInstance(kinematics_data, quaternion_data, velocity_data, acceleration_data):\n",
    "\n",
    "    # get imu data at time index\n",
    "    new_IMU_instance = createIMUDataInstance(quaternion_data, velocity_data, acceleration_data, orientation_only=True)\n",
    "    right_arm_kinematics = kinematics_data.values[:, 26:31]\n",
    "    left_arm_kinematics = kinematics_data.values[:, 33:38]\n",
    "    right_leg_kinematics = kinematics_data.values[:, 7:13]\n",
    "    left_leg_kinematics = kinematics_data.values[:, 15:21]\n",
    "    torso_kinematics = np.concatenate([kinematics_data.values[:, 1:7],  kinematics_data.values[:, 23:26]], axis=1)\n",
    "    new_kinematics_instance = np.concatenate([left_arm_kinematics, \n",
    "                                              right_arm_kinematics,\n",
    "                                            #   left_leg_kinematics,\n",
    "                                            #   right_leg_kinematics,\n",
    "                                              torso_kinematics], axis = 1)\n",
    "\n",
    "    print(\"Kinematics Dimensions: \", new_kinematics_instance.shape)\n",
    "    print(\"IMU Dimensions: \", new_IMU_instance.shape)\n",
    "    # concatenate and return\n",
    "    new_data_instance = np.concatenate([new_kinematics_instance, new_IMU_instance], axis=1)\n",
    "    print(\"Concatenated Dimensions: \", new_data_instance.shape)\n",
    "    return new_data_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_temporal_minus_one(data):\n",
    "    r = data.shape[0]\n",
    "    c = data.shape[1]\n",
    "\n",
    "    res = np.zeros((r-1, c*2))\n",
    "    for j in range(c):\n",
    "        res[:, j*2] = data[1:, j]\n",
    "        res[:, j*2+1] = data[0:r-1, j]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_temporal_plus_one(data):\n",
    "    r = data.shape[0]\n",
    "    c = data.shape[1]\n",
    "\n",
    "    res = np.zeros((r-1, c*2))\n",
    "    for j in range(c):\n",
    "        res[:, j*2] = data[0:r-1, j]\n",
    "        res[:, j*2+1] = data[1:, j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(data):\n",
    "    r = data.shape[0]\n",
    "    c = data.shape[1]\n",
    "    res = np.copy(data)\n",
    "\n",
    "    for j in range(0, 38, 2):\n",
    "        res[:, j] = -2\n",
    "    return np.vstack((data, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(trial_num, trial_type):\n",
    "\n",
    "    filepath = \"/home/franklin/Research\"\n",
    "    # Local: /Users/FranklinZhao/Research\n",
    "    # SSH: /home/franklin/Research\n",
    "\n",
    "\n",
    "\n",
    "    # load IMU data, non-filtered\n",
    "    # quaternion_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/Rajapogal_FullBody_calibrated_orientations.sto\"\n",
    "    # velocity_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/Rajapogal_FullBody_calibrated_angular_velocity.sto\"\n",
    "    # acceleration_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/Rajapogal_FullBody_calibrated_linear_accelerations.sto\"\n",
    "\n",
    "    # load IMU data, filtered\n",
    "    quaternion_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/filtered_orientations.sto\"\n",
    "    velocity_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/filtered_angular_velocity.sto\"\n",
    "    acceleration_path = f\"{filepath}/Dataset/vIMU/Experimental/{trial_type}_{trial_num}/filtered_linear_accelerations.sto\"\n",
    "\n",
    "    # read IMU data into dataframes\n",
    "    quaternion_data = pd.read_csv(filepath_or_buffer=quaternion_path, sep='\\t', header=4)\n",
    "    velocity_data = pd.read_csv(filepath_or_buffer=velocity_path, sep='\\t', header=4)\n",
    "    acceleration_data = pd.read_csv(filepath_or_buffer=acceleration_path, sep='\\t', header=4)\n",
    "\n",
    "    # load kinematics data\n",
    "    kinematics_path = f\"{filepath}/Dataset/Motion/Experimental/{trial_type}_0{trial_num}.mot\"\n",
    "\n",
    "    # read kinematics data into dataframes\n",
    "    kinematics_data = pd.read_csv(filepath_or_buffer=kinematics_path, header=8, skipinitialspace=True, sep='\\t')    \n",
    "\n",
    "    # create data instance\n",
    "    new_data_instance = formatDataInstance(kinematics_data, quaternion_data, velocity_data, acceleration_data)\n",
    "    # scale data instance\n",
    "    new_data_instance = scaleDataInstance(new_data_instance)\n",
    "    # new_data_instance = augment_temporal_minus_one(new_data_instance)\n",
    "    # new_data_instance = mask(new_data_instance)\n",
    "    print(new_data_instance.shape)\n",
    "\n",
    "    # save data instance\n",
    "    df = pd.DataFrame(new_data_instance)\n",
    "    file_path = f'{filepath}/data_instance_{trial_num}.csv'\n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "    print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset 1\n",
      "Kinematics Dimensions:  (7510, 19)\n",
      "IMU Dimensions:  (7510, 16)\n",
      "Concatenated Dimensions:  (7510, 35)\n",
      "(7510, 35)\n",
      "saved!\n",
      "Creating Dataset 2\n",
      "Kinematics Dimensions:  (5405, 19)\n",
      "IMU Dimensions:  (5405, 16)\n",
      "Concatenated Dimensions:  (5405, 35)\n",
      "(5405, 35)\n",
      "saved!\n",
      "Creating Dataset 3\n",
      "Kinematics Dimensions:  (5203, 19)\n",
      "IMU Dimensions:  (5203, 16)\n",
      "Concatenated Dimensions:  (5203, 35)\n",
      "(5203, 35)\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "# trial data\n",
    "trial_type = \"tug\"\n",
    "for i in range(1, 4):\n",
    "    print(f\"Creating Dataset {i}\")\n",
    "    createDataset(i, trial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
